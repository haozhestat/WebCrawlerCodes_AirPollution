
R version 2.14.2 (2012-02-29)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> setwd("/data/zoutao/crontab")
> require("XML")
Loading required package: XML
> require("RCurl")
Loading required package: RCurl
Loading required package: bitops
> require("tmcn")
Loading required package: tmcn
# tmcn Version: 0.1-3
> 
> #for (i in 1:1){
>   
> #  tryCatch({
> 
> 
> result=matrix(0,nrow=1,ncol=12+11*10)
> result=as.data.frame(result)
> 
> 
> 
> z="http://aqicn.org/city/hongkong/central/cn/m/"
> 
> 
> #z="http://aqicn.org/city/beijing/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> stat[sapply(stat, is.null)] <- NA 
> 
> result[1,2]=up_time
> result[1,3:12]=stat
> 
> 
> z="http://aqicn.org/city/beijing/qianmendongdajie/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> stat[sapply(stat, is.null)] <- NA 
> 
> result[1,(2+11)]=up_time
> result[1,(3+11):(12+11)]=stat
> 
> 
> 
> 
> 
> z="http://aqicn.org/city/beijing/chaoyangaotizhongxin/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> stat[sapply(stat, is.null)] <- NA 
> 
> result[1,(2+11*2)]=up_time
> result[1,(3+11*2):(12+11*2)]=stat
> 
> 
> z="http://aqicn.org/city/beijing/haidianwanliu/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> 
> stat[sapply(stat, is.null)] <- NA 
> result[1,(2+11*3)]=up_time
> result[1,(3+11*3):(12+11*3)]=stat
> 
> 
> 
> z="http://aqicn.org/city/beijing/fengtaihuayuan/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> #stat$`//tr[contains(@id,'tr_o3')]/td`="Null"
> stat[sapply(stat, is.null)] <- NA 
> result[1,(2+11*4)]=up_time
> result[1,(3+11*4):(12+11*4)]=stat
> 
> 
> 
> 
> z="http://aqicn.org/city/beijing/nansanhuanxilu/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> stat[sapply(stat, is.null)] <- NA 
> 
> result[1,(2+11*5)]=up_time
> result[1,(3+11*5):(12+11*5)]=stat
> 
> 
> 
> 
> z="http://aqicn.org/city/beijing/shijingshangucheng/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> stat[sapply(stat, is.null)] <- NA 
> 
> result[1,(2+11*6)]=up_time
> result[1,(3+11*6):(12+11*6)]=stat
> 
> 
> 
> z="http://aqicn.org/city/beijing/daxinghuangcunzhen/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> stat[sapply(stat, is.null)] <- NA 
> 
> result[1,(2+11*7)]=up_time
> result[1,(3+11*7):(12+11*7)]=stat
> 
> 
> z="http://aqicn.org/city/beijing/tongzhouxincheng/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> stat[sapply(stat, is.null)] <- NA 
> 
> result[1,(2+11*8)]=up_time
> result[1,(3+11*8):(12+11*8)]=stat
> 
> 
> 
> 
> z="http://aqicn.org/city/beijing/shunyixincheng/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> #stat$`//tr[contains(@id,'tr_no2')]/td`="Null"
> stat[sapply(stat, is.null)] <- NA 
> result[1,(2+11*9)]=up_time
> result[1,(3+11*9):(12+11*9)]=stat
> 
> 
> z="http://aqicn.org/city/beijing/changpingzhen/cn/m/"
> 
> #a=read.table(z)
> 
> url = getURL(z,.encoding="UTF-8")
> 
> url = toUTF8(url)
> chinese = c("更新时间",paste("星期",c("一","二","三","四","五","六","日","天"),sep=""))
> weekday = c("Update_time","Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday","Sunday")
> 
> for (i in 1:length(chinese))
+ {
+   url = gsub(chinese[i],weekday[i],url)
+ }
> 
> url=gsub('font-size:12px;color:#888;','font-size:12px;color:#888888;',url)
> 
> tmp = htmlTreeParse(url,useInternalNodes=T)
> 
> up_time = xpathSApply(tmp,
+                       "//div[contains(@style,'font-size:12px;color:#888888;')]",
+                       xmlValue)
> up_time = unlist(strsplit(up_time,split=" "))[2]
> 
> index = paste("tr",c("pm25","pm10","o3","no2","so2","t","d","p","h","w"),sep="_")
> path = paste("//tr[contains(@id,'",index,"')]/td",sep="")
> stat = sapply(path,function(x){
+   res = xpathSApply(tmp,x,xmlValue)
+   rr = res[(length(res)-3):length(res)][1]
+   return(rr)
+ })
> 
> stat[sapply(stat, is.null)] <- NA 
> 
> result[1,(2+11*10)]=up_time
> result[1,(3+11*10):(12+11*10)]=stat
> 
> 
> 
> 
> 
> Time = Sys.time()
> pb.date <- as.POSIXct(Time, tz="America/Chicago")
> Time=format(pb.date, tz="Asia/Shanghai", "%D %H:%M")
> result[1,1]=Time
> 
> write.table(result,file='/data/zoutao/crontab/pm2.5new.csv',col.names = FALSE,row.names=F,quote=F,sep=",",append=TRUE)
> 
> 
> 
> 
> 
> 
> #  }, error=function(e){})
> #}
> 
> 
> 
> 
> proc.time()
   user  system elapsed 
  1.883   0.077  13.965 
Warning message:
In save(list = ls(envir = .GlobalEnv, all.names = TRUE), file = outfile,  :
  'package:tmcn' may not be available when loading
